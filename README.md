The L2 Analytics Project is an end-to-end, AI-driven analytics and reporting platform designed to transform raw, unstructured, and multimodal data into meaningful insights, reports, and visual narratives. The platform focuses on advanced data analysis, intelligent report generation, semantic search, and interactive data storytelling, enabling users to extract value from documents, folders, chats, links, and video content.

Built on a hybrid architecture, the system combines Node.js for APIs, middleware, authentication, and orchestration with Python-based AI and data processing pipelines for NLP, OCR, analytics, and machine learning. This architecture ensures scalability, modular growth, and seamless integration of future technologies.

The project follows a phase-wise implementation strategy, starting with a strong infrastructure foundation and gradually introducing advanced AI capabilities. Early phases focus on document ingestion, metadata management, keyword search, and basic report generation. Subsequent phases enhance intelligence through RAG pipelines, vector databases (ChromaDB), AI agents, folder-level analytics, and multimodal understanding of chats, links, and videos.

As the platform evolves, it introduces interactive dashboards, graphical representations, search-driven visual analytics, and semantic search, allowing users to explore insights visually rather than through static logs. Advanced phases emphasize data storytelling, anomaly detection, trend forecasting, and narrative-based insights generated by LLM agents.

Overall, the L2 Analytics Project aims to deliver a future-ready analytics ecosystem that not only analyzes data but also explains itâ€”helping users make faster, more informed, and decision-ready insights through automation, intelligence, and visualization.

**Installing the libraries**

**1. Node Backend**
npm i or npm install
This will install the libraries related to node 

**2. Python Backend**

pip install -r requirements.txt 
pip install fastapi easyocr spacy langchain langchain-community langchain-core llama_index pymongo dotenv requests 

**3. Frontend Library Install**

npm i or npm install

**Running the backend and frontend**

**1. Node Backend running**
npm start or npm run dev 

**2.Python Backend running**
uvicorn app.main:app --reload --host 127.0.0.1 --port 5000

**3.Frontend running**
npm run dev
